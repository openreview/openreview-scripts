{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import openreview\n",
    "import re\n",
    "import unicodecsv as csv\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = openreview.Client(username=\"OpenReview.net\",password=\"OpenReview_beta\",baseurl=\"http://openreview.net\")\n",
    "\n",
    "outputdir = './tpms-dump-final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_profiles(groupname):\n",
    "    print \"groupname:\",groupname\n",
    "    members = client.get_group(groupname).members\n",
    "    \n",
    "    p = re.compile('~.*')\n",
    "\n",
    "    canonical_ids = []\n",
    "    missing_users = []\n",
    "    for m in members:\n",
    "        m = m.strip()\n",
    "        try:\n",
    "            print('m:',m)\n",
    "            client.get_group(m)\n",
    "            g = client.get_group(m)\n",
    "            groupmembers = [member for member in g.members if p.match(member)]\n",
    "\n",
    "            if len(groupmembers) ==0:\n",
    "                print \"No canonical IDs found for member \",m\n",
    "                missing_users.append(m)\n",
    "            else:\n",
    "                if len(groupmembers) > 1:\n",
    "                    print \"More than one canonical ID found for member \",m,\"; Using first ID in the list.\"\n",
    "\n",
    "                tildeId = groupmembers[0]\n",
    "                canonical_ids.append(tildeId)\n",
    "\n",
    "        except openreview.OpenReviewException as e:\n",
    "            missing_users.append(m)\n",
    "            print e\n",
    "\n",
    "    profiles = []\n",
    "\n",
    "    for id in canonical_ids:\n",
    "        print \"id: \",id\n",
    "        profiles.append(client.get_note(id).to_json())\n",
    "    \n",
    "    return profiles,missing_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_names(profiles,outfilename,missingTuple=None):\n",
    "    if not os.path.exists(outputdir):\n",
    "        os.makedirs(outputdir)\n",
    "\n",
    "    with open(outputdir+'/'+outfilename,'wb') as outfile:\n",
    "        csvwriter = csv.writer(outfile, delimiter=',')\n",
    "        for profile in profiles:\n",
    "            p = profile['content']\n",
    "            name = p['names'][0]\n",
    "            firstname = name['first']\n",
    "            lastname = name['last']\n",
    "            email = p['emails'][0]\n",
    "            csvwriter.writerow([email,firstname,lastname])\n",
    "        if missingTuple !=None:\n",
    "            missingList = missingTuple[0]\n",
    "            missingMap = missingTuple[1]\n",
    "            for email in missingList:\n",
    "                try:\n",
    "                    csvwriter.writerow([email,missingMap[email][0],missingMap[email][1]])\n",
    "                except KeyError as e:\n",
    "                    print \"Key error found on email \",email,': ',e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_pdfs(papers):\n",
    "    external = re.compile('http.*')\n",
    "    internal = re.compile('\\/pdf\\/.*')\n",
    "    for s in papers:\n",
    "        if external.match(s['content']['pdf']):\n",
    "            r = requests.get(s['content']['pdf'])\n",
    "        elif(internal.match(s['content']['pdf'])):\n",
    "            r = requests.get(client.baseurl+'/pdf?id='+s['id'], headers=client.headers)\n",
    "        else:\n",
    "            print \"Couldn't get PDF for note \",s['id']\n",
    "            \n",
    "        print \"number\",s['number'],\"response\",r\n",
    "        if not os.path.exists(outputdir+'/pdfs'):\n",
    "            os.makedirs(outputdir+'/pdfs')\n",
    "        with open(outputdir+'/pdfs/paper'+str(s['number'])+'.pdf', 'wb') as f:\n",
    "            f.write(r.content)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_conflicts(profile):\n",
    "    conflicts = set()\n",
    "    for h in profile['content']['history']:\n",
    "        conflicts.add(h['institution']['domain'])\n",
    "    for e in profile['content']['emails']:\n",
    "        domain = e.split('@')[1]\n",
    "        conflicts.add(domain)\n",
    "    return conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dump_conflicts(profiles, missing, papers, outfilename):\n",
    "    with open(outputdir+'/'+outfilename,'wb') as outfile:\n",
    "        csvwriter=csv.writer(outfile,delimiter=',')\n",
    "        for profile in profiles:\n",
    "            email = profile['content']['emails'][0]\n",
    "            profile_conflicts = get_conflicts(profile)\n",
    "            for paper in papers:\n",
    "                paper_id = str(paper['number'])\n",
    "                if not profile_conflicts.isdisjoint(paper['content']['conflicts']):\n",
    "                    print \"conflict detected:\",email,profile_conflicts,paper['content']['conflicts']\n",
    "                    csvwriter.writerow([paper_id,email])\n",
    "        \n",
    "        for email in missing:\n",
    "            domain = email.split('@')[1]\n",
    "            for paper in papers:\n",
    "                paper_id = str(paper['number'])\n",
    "                if domain in paper['content']['conflicts']:\n",
    "                    csvwriter.writerow([paper_id,email])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_missing(list):\n",
    "    with open(outputdir+'/missing-dump.csv','wb') as outfile:\n",
    "        for email in list:\n",
    "            csvwriter=csv.writer(outfile,delimiter=',')\n",
    "            first = all_reviewers[email][0]\n",
    "            last = all_reviewers[email][1]\n",
    "            csvwriter.writerow([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client.user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviewer_profiles,missing_reviewers = get_profiles(\"ICLR.cc/2017/conference/reviewers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviewer_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "areachair_profiles,missing_areachairs = get_profiles(\"ICLR.cc/2017/areachairs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_areachairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missingReviewerMap = {}\n",
    "with open('./iclr_all_reviewers.csv', 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    c=0\n",
    "    for row in reader:\n",
    "        if c>0:\n",
    "            print row\n",
    "            missingReviewerMap[str(row[2])]=row[0:2]\n",
    "        c+=1\n",
    "        \n",
    "missingAreachairMap = {}\n",
    "with open('./iclr_area_chairs.csv', 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    c=0\n",
    "    for row in reader:\n",
    "        if c>0:\n",
    "            print row\n",
    "            missingAreachairMap[str(row[2])]=row[0:2]\n",
    "        c+=1\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "papers = [s.to_json() for s in client.get_notes(invitation='ICLR.cc/2017/conference/-/submission')]\n",
    "\n",
    "        \n",
    "dump_names(reviewer_profiles,\"reviewer-dump.csv\",(missing_reviewers,missingReviewerMap))\n",
    "dump_names(areachair_profiles,\"areachair-dump.csv\",(missing_areachairs,missingAreachairMap))\n",
    "write_pdfs(papers)\n",
    "dump_conflicts(reviewer_profiles,missing_reviewers+missing_areachairs,papers,\"conflicts-dump.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (openreview)",
   "language": "python",
   "name": "openreview"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
